{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "041fe318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4433758481980190841\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5750390784\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3277636562185094230\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7014db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5038aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "image_dir = 'D:/python-ai-data/232.재활용품 분류 및 선별 데이터/01.데이터/data/images/'\n",
    "image_dir_target = 'D:/python-ai-data/232.재활용품 분류 및 선별 데이터/01.데이터/train/images/'\n",
    "item_image_list = os.listdir(image_dir)\n",
    "\n",
    "for item in item_image_list:\n",
    "    shutil.copytree(image_dir+item+'/images0/', image_dir_target, dirs_exist_ok=True)\n",
    "    shutil.copytree(image_dir+item+'/images1/', image_dir_target, dirs_exist_ok=True)\n",
    "    shutil.copytree(image_dir+item+'/images2/', image_dir_target, dirs_exist_ok=True)\n",
    "    shutil.copytree(image_dir+item+'/images3/', image_dir_target, dirs_exist_ok=True)\n",
    "\n",
    "label_dir = 'D:/python-ai-data/232.재활용품 분류 및 선별 데이터/01.데이터/data/labels/'\n",
    "label_dir_target = 'D:/python-ai-data/232.재활용품 분류 및 선별 데이터/01.데이터/train/labels_json/'\n",
    "item_label_list = os.listdir(label_dir)\n",
    "\n",
    "for item in item_label_list:\n",
    "    shutil.copytree(label_dir+item+'/labels0/', label_dir_target, dirs_exist_ok=True)\n",
    "    shutil.copytree(label_dir+item+'/labels1/', label_dir_target, dirs_exist_ok=True)\n",
    "    shutil.copytree(label_dir+item+'/labels2/', label_dir_target, dirs_exist_ok=True)\n",
    "    shutil.copytree(label_dir+item+'/labels3/', label_dir_target, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c4a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_dir = 'D:/python-ai-data/232.재활용품 분류 및 선별 데이터/01.데이터'\n",
    "\n",
    "train_images_path = base_dir + '/train/images/'\n",
    "train_labels_json_path = base_dir + '/train/labels_json/'\n",
    "train_labels_path = base_dir + '/train/labels/'\n",
    "\n",
    "os.makedirs(train_images_path, exist_ok=True)\n",
    "os.makedirs(train_labels_json_path, exist_ok=True)\n",
    "os.makedirs(train_labels_path, exist_ok=True)\n",
    "\n",
    "# !unzip -qq '/content/drive/MyDrive/KCC3기_2차_프로젝트/train.zip' -d '/content/data/train'\n",
    "\n",
    "train_images_list = os.listdir(train_images_path)\n",
    "train_labels_json_list = os.listdir(train_labels_json_path)\n",
    "\n",
    "train_images_list.sort()\n",
    "train_labels_json_list.sort()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "449bd9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 train data를 변환하기 - 라벨링 변환\n",
    "\n",
    "yolo_class = {\n",
    "    '철캔': 0,\n",
    "    '알루미늄캔': 4,\n",
    "    '종이': 8,\n",
    "    '무색단일': 12,\n",
    "    '유색단일': 16,\n",
    "    'PE': 20,\n",
    "    'PP': 24,\n",
    "    'PS': 28,\n",
    "    '스티로폼': 32,\n",
    "    '비닐': 36,\n",
    "    '갈색': 40,\n",
    "    '녹색': 44,\n",
    "    '투명': 48\n",
    "}\n",
    "\n",
    "for label in train_labels_json_list:\n",
    "    file_json = open(train_labels_json_path + label, encoding='UTF-8')\n",
    "    f_json = json.load(file_json)\n",
    "\n",
    "    img_width = f_json['IMAGE_INFO']['IMAGE_WIDTH']\n",
    "    img_height = f_json['IMAGE_INFO']['IMAGE_HEIGHT']\n",
    "\n",
    "    f_txt = open(train_labels_path + label.replace('.json', '.txt'), 'w')\n",
    "\n",
    "    for anno in f_json['ANNOTATION_INFO']:\n",
    "        obj_id = yolo_class[anno['DETAILS']]\n",
    "\n",
    "        if anno['DAMAGE'] != '원형':\n",
    "            obj_id += 2\n",
    "        if anno['DIRTINESS'] != '오염없음':\n",
    "            obj_id += 1\n",
    "\n",
    "        obj_points = np.array(anno['POINTS'])\n",
    "        if obj_points[0].size == 4:\n",
    "            yolo_id = obj_id\n",
    "            yolo_points = np.array([obj_points[0][0]+obj_points[0][2]/2, obj_points[0][1]+obj_points[0][3]/2,\n",
    "                                    obj_points[0][2], obj_points[0][3]])\n",
    "\n",
    "            yolo_points_norm = np.array([yolo_points[0]/img_width, yolo_points[1]/img_height,\n",
    "                             yolo_points[2]/img_width, yolo_points[3]/img_height])\n",
    "\n",
    "            yolo_points_norm = list(yolo_points_norm)\n",
    "            f_txt.write(str(yolo_id) + ' ')\n",
    "            f_txt.write(' '.join(str(ele) for ele in yolo_points_norm))\n",
    "            f_txt.write('\\n')\n",
    "        elif obj_points.size >= 2:\n",
    "            max_x = 0\n",
    "            min_x = img_width\n",
    "            max_y = 0\n",
    "            min_y = img_height\n",
    "            for points in obj_points:\n",
    "                if points[0] > max_x:\n",
    "                    max_x = points[0]\n",
    "                if points[0] < min_x:\n",
    "                    min_x = points[0]\n",
    "                if points[1] > max_y:\n",
    "                    max_y = points[1]\n",
    "                if points[1] < min_y:\n",
    "                    min_y = points[1]\n",
    "\n",
    "            yolo_id = obj_id\n",
    "            yolo_points = np.array([(min_x+max_x)/2, (min_y+max_y)/2,\n",
    "                              max_x-min_x, max_y-min_y])\n",
    "            yolo_points_norm = np.array([yolo_points[0]/img_width, yolo_points[1]/img_height,\n",
    "                                         yolo_points[2]/img_width, yolo_points[3]/img_height])\n",
    "            yolo_points_norm = list(yolo_points_norm)\n",
    "\n",
    "            f_txt.write(str(yolo_id) + ' ')\n",
    "            f_txt.write(' '.join(str(ele) for ele in yolo_points_norm))\n",
    "            f_txt.write('\\n')\n",
    "        else:\n",
    "            print(label)\n",
    "    f_txt.close()\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json 라벨 삭제 및 라벨링 확인\n",
    "\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(train_labels_json_path)\n",
    "\n",
    "# print(open('/content/data/train/labels/606511@4_04002_220907_P1_T1.txt').readline())\n",
    "# print(open('/content/data/train/labels/10349@3_01001_220715_P1_T1.txt').readline())\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9af9d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation 데이터 분리\n",
    "\n",
    "import shutil\n",
    "\n",
    "val_images_path = base_dir + '/val/images/'\n",
    "val_labels_path = base_dir + '/val/labels/'\n",
    "\n",
    "os.makedirs(val_images_path, exist_ok=True)\n",
    "os.makedirs(val_labels_path, exist_ok=True)\n",
    "\n",
    "train_images_list = os.listdir(train_images_path)\n",
    "train_labels_list = os.listdir(train_labels_path)\n",
    "\n",
    "train_images_list.sort()\n",
    "train_labels_list.sort()\n",
    "\n",
    "for i in range(len(train_images_list)):\n",
    "    if i % 10 == 0:\n",
    "        shutil.move(train_images_path + train_images_list[i], val_images_path)\n",
    "        shutil.move(train_labels_path + train_labels_list[i], val_labels_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a84fded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77356\n",
      "77356\n",
      "8596\n",
      "8596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분리한 데이터 이미지와 라벨 파일 일치 여부 확인\n",
    "\n",
    "print(len(os.listdir(train_images_path)))\n",
    "print(len(os.listdir(train_labels_path)))\n",
    "\n",
    "print(len(os.listdir(val_images_path)))\n",
    "print(len(os.listdir(val_labels_path)))\n",
    "\n",
    "train_images_list = os.listdir(train_images_path)\n",
    "train_labels_list = os.listdir(train_labels_path)\n",
    "\n",
    "train_images_list.sort()\n",
    "train_labels_list.sort()\n",
    "\n",
    "for i in range(len(train_images_list)):\n",
    "    if train_images_list[i].replace('.jpg', '') != train_labels_list[i].replace('.txt', ''):\n",
    "        print(train_images_list[i])\n",
    "\n",
    "val_images_list = os.listdir(val_images_path)\n",
    "val_labels_list = os.listdir(val_labels_path)\n",
    "\n",
    "val_images_list.sort()\n",
    "val_labels_list.sort()\n",
    "\n",
    "print()\n",
    "for i in range(len(val_images_list)):\n",
    "    if val_images_list[i].replace('.jpg', '') != val_labels_list[i].replace('.txt', ''):\n",
    "        print(val_images_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948fc025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyYAML in c:\\users\\00006\\anaconda3\\envs\\data_env\\lib\\site-packages (6.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'names': ['IronCan_NoDamNoDir',\n",
       "  'IronCan_NoDamDir',\n",
       "  'IronCan_DamNoDir',\n",
       "  'IronCan_DamDir',\n",
       "  'AluminumCan_NoDamNoDir',\n",
       "  'AluminumCan_NoDamDir',\n",
       "  'AluminumCan_DamNoDir',\n",
       "  'AluminumCan_DamDir',\n",
       "  'Paper_NoDamNoDir',\n",
       "  'Paper_NoDamDir',\n",
       "  'Paper_DamNoDir',\n",
       "  'Paper_DamDir',\n",
       "  'PetNoColor_NoDamNoDir',\n",
       "  'PetNoColor_NoDamDir',\n",
       "  'PetNoColor_DamNoDir',\n",
       "  'PetNoColor_DamDir',\n",
       "  'PetColor_NoDamNoDir',\n",
       "  'PetColor_NoDamDir',\n",
       "  'PetColor_DamNoDir',\n",
       "  'PetColor_DamDir',\n",
       "  'PE_NoDamNoDir',\n",
       "  'PE_NoDamDir',\n",
       "  'PE_DamNoDir',\n",
       "  'PE_DamDir',\n",
       "  'PP_NoDamNoDir',\n",
       "  'PP_NoDamDir',\n",
       "  'PP_DamNoDir',\n",
       "  'PP_DamDir',\n",
       "  'PS_NoDamNoDir',\n",
       "  'PS_NoDamDir',\n",
       "  'PS_DamNoDir',\n",
       "  'PS_DamDir',\n",
       "  'Styrofoam_NoDamNoDir',\n",
       "  'Styrofoam_NoDamDir',\n",
       "  'Styrofoam_DamNoDir',\n",
       "  'Styrofoam_DamDir',\n",
       "  'Vinyl_NoDamNoDir',\n",
       "  'Vinyl_NoDamDir',\n",
       "  'Vinyl_DamNoDir',\n",
       "  'Vinyl_DamDir',\n",
       "  'GlassBrown_NoDamNoDir',\n",
       "  'GlassBrown_NoDamDir',\n",
       "  'GlassBrown_DamNoDir',\n",
       "  'GlassBrown_DamDir',\n",
       "  'GlassGreen_NoDamNoDir',\n",
       "  'GlassGreen_NoDamDir',\n",
       "  'GlassGreen_DamNoDir',\n",
       "  'GlassGreen_DamDir',\n",
       "  'GlassTransparency_NoDamNoDir',\n",
       "  'GlassTransparency_NoDamDir',\n",
       "  'GlassTransparency_DamNoDir',\n",
       "  'GlassTransparency_DamDir'],\n",
       " 'nc': 52,\n",
       " 'train': 'D:/python-ai-data/train/images/',\n",
       " 'val': 'D:/python-ai-data/val/images/'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install PyYAML\n",
    "\n",
    "import yaml\n",
    "\n",
    "data = {\n",
    "    'train': 'D:/python-ai-data/train/images/',\n",
    "    'val': 'D:/python-ai-data/val/images/',\n",
    "    'names': ['IronCan_NoDamNoDir', 'IronCan_NoDamDir', 'IronCan_DamNoDir', 'IronCan_DamDir',\n",
    "              'AluminumCan_NoDamNoDir', 'AluminumCan_NoDamDir', 'AluminumCan_DamNoDir', 'AluminumCan_DamDir',\n",
    "              'Paper_NoDamNoDir', 'Paper_NoDamDir', 'Paper_DamNoDir', 'Paper_DamDir',\n",
    "              'PetNoColor_NoDamNoDir', 'PetNoColor_NoDamDir', 'PetNoColor_DamNoDir', 'PetNoColor_DamDir',\n",
    "              'PetColor_NoDamNoDir', 'PetColor_NoDamDir', 'PetColor_DamNoDir', 'PetColor_DamDir',\n",
    "              'PE_NoDamNoDir', 'PE_NoDamDir', 'PE_DamNoDir', 'PE_DamDir',\n",
    "              'PP_NoDamNoDir', 'PP_NoDamDir', 'PP_DamNoDir', 'PP_DamDir',\n",
    "              'PS_NoDamNoDir', 'PS_NoDamDir', 'PS_DamNoDir', 'PS_DamDir',\n",
    "              'Styrofoam_NoDamNoDir', 'Styrofoam_NoDamDir', 'Styrofoam_DamNoDir', 'Styrofoam_DamDir',\n",
    "              'Vinyl_NoDamNoDir', 'Vinyl_NoDamDir', 'Vinyl_DamNoDir', 'Vinyl_DamDir',\n",
    "              'GlassBrown_NoDamNoDir', 'GlassBrown_NoDamDir', 'GlassBrown_DamNoDir', 'GlassBrown_DamDir',\n",
    "              'GlassGreen_NoDamNoDir', 'GlassGreen_NoDamDir', 'GlassGreen_DamNoDir', 'GlassGreen_DamDir',\n",
    "              'GlassTransparency_NoDamNoDir', 'GlassTransparency_NoDamDir', 'GlassTransparency_DamNoDir', 'GlassTransparency_DamDir'],\n",
    "    'nc': 52\n",
    "}\n",
    "\n",
    "yaml_name = 'recycle_data.yaml'\n",
    "with open('D:/python-ai-data/' + 'recycle_data.yaml', 'w') as f:\n",
    "    yaml.dump(data, f)\n",
    "\n",
    "with open('D:/python-ai-data/' + 'recycle_data.yaml', 'r') as f:\n",
    "    recycle_yaml = yaml.safe_load(f)\n",
    "    display(recycle_yaml)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a528b29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.159  Python-3.8.17 torch-2.0.0+cu117 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "Setup complete  (12 CPUs, 31.8 GB RAM, 1336.1/1863.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# YOLO 학습 위한 환경\n",
    "\n",
    "# %pip install ultralytics\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb9d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.159  Python-3.8.17 torch-2.0.0+cu117 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=D:/python-ai-data/recycle_data.yaml, epochs=1, patience=3, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=recycle, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\recycle\n",
      "Overriding model.yaml nc=80 with nc=52\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    761452  ultralytics.nn.modules.head.Detect           [52, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3020988 parameters, 3020972 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\recycle', view at http://localhost:6006/\n",
      "WARNING  TensorBoard graph visualization failure __init__() got an unexpected keyword argument 'category'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\python-ai-data\\train\\labels.cache... 77356 images, 0 backgrounds, 1 corrupt: 100%|██████████| 77356/\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\python-ai-data\\train\\images\\1263722@0_07002_220822_P1_T3__0700.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0022]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\python-ai-data\\val\\labels.cache... 8596 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8596/8596 [\u001b[0m\n",
      "Plotting labels to runs\\detect\\recycle\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000179, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\recycle\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/1      9.41G     0.6732      3.451      1.174         88        640: 100%|██████████| 1209/1209 [31:02<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [01:50\n",
      "                   all       8596       9831      0.412      0.325      0.234      0.211\n",
      "\n",
      "1 epochs completed in 0.549 hours.\n",
      "Optimizer stripped from runs\\detect\\recycle\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from runs\\detect\\recycle\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating runs\\detect\\recycle\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.159  Python-3.8.17 torch-2.0.0+cu117 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "Model summary (fused): 168 layers, 3015788 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 68/68 [00:43\n",
      "                   all       8596       9831      0.411      0.326      0.234      0.211\n",
      "    IronCan_NoDamNoDir       8596        467      0.301      0.861      0.431      0.419\n",
      "      IronCan_NoDamDir       8596        665      0.335      0.872      0.519      0.485\n",
      "      IronCan_DamNoDir       8596        122      0.205      0.205      0.163      0.161\n",
      "        IronCan_DamDir       8596        156      0.192      0.378      0.189      0.187\n",
      "AluminumCan_NoDamNoDir       8596        138      0.241      0.029      0.103      0.085\n",
      "  AluminumCan_NoDamDir       8596         48          1          0     0.0196     0.0186\n",
      "  AluminumCan_DamNoDir       8596        218      0.289      0.743      0.385      0.361\n",
      "    AluminumCan_DamDir       8596         81      0.486     0.0741      0.226       0.22\n",
      "      Paper_NoDamNoDir       8596        219      0.339      0.758      0.462      0.421\n",
      "        Paper_NoDamDir       8596         46          0          0      0.106     0.0984\n",
      "        Paper_DamNoDir       8596        290      0.349      0.831      0.483      0.435\n",
      "          Paper_DamDir       8596         48          1          0     0.0183     0.0167\n",
      " PetNoColor_NoDamNoDir       8596         54      0.152     0.0556      0.134      0.123\n",
      "   PetNoColor_NoDamDir       8596        266      0.325      0.759      0.408      0.368\n",
      "   PetNoColor_DamNoDir       8596         63      0.489      0.444      0.562       0.54\n",
      "     PetNoColor_DamDir       8596        116      0.321      0.724      0.404      0.373\n",
      "   PetColor_NoDamNoDir       8596         94          0          0     0.0421     0.0388\n",
      "     PetColor_NoDamDir       8596        310       0.24        0.3      0.222      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     PetColor_DamNoDir       8596         53      0.249      0.264      0.165      0.163\n",
      "       PetColor_DamDir       8596        106      0.182       0.34      0.199      0.191\n",
      "         PE_NoDamNoDir       8596         40          1          0     0.0432     0.0429\n",
      "           PE_NoDamDir       8596        310      0.346      0.735      0.474      0.428\n",
      "           PE_DamNoDir       8596         17          1          0    0.00606     0.0045\n",
      "             PE_DamDir       8596         31          1          0     0.0157     0.0154\n",
      "         PP_NoDamNoDir       8596        300      0.394      0.793      0.543      0.479\n",
      "           PP_NoDamDir       8596        241      0.267      0.477      0.289      0.243\n",
      "           PP_DamNoDir       8596         88      0.272      0.261      0.198      0.185\n",
      "             PP_DamDir       8596         49          0          0     0.0299     0.0276\n",
      "         PS_NoDamNoDir       8596        211      0.344       0.45      0.313      0.294\n",
      "           PS_NoDamDir       8596        305      0.288      0.495      0.302      0.276\n",
      "           PS_DamNoDir       8596         46          1          0     0.0707     0.0614\n",
      "             PS_DamDir       8596         55          1          0     0.0524     0.0437\n",
      "  Styrofoam_NoDamNoDir       8596        267      0.466       0.67      0.604      0.555\n",
      "    Styrofoam_NoDamDir       8596         81      0.328     0.0247       0.11      0.102\n",
      "    Styrofoam_DamNoDir       8596        126      0.171      0.421      0.139      0.107\n",
      "      Styrofoam_DamDir       8596        124      0.231      0.524      0.243      0.203\n",
      "      Vinyl_NoDamNoDir       8596         91      0.155      0.451      0.186      0.175\n",
      "        Vinyl_NoDamDir       8596         85        0.2      0.118      0.172      0.162\n",
      "        Vinyl_DamNoDir       8596        309       0.39      0.906      0.562      0.522\n",
      "          Vinyl_DamDir       8596         48          0          0     0.0644     0.0589\n",
      " GlassBrown_NoDamNoDir       8596         66          1          0      0.113      0.107\n",
      "   GlassBrown_NoDamDir       8596       1139      0.429      0.831       0.63      0.504\n",
      "   GlassBrown_DamNoDir       8596          1          1          0          0          0\n",
      "     GlassBrown_DamDir       8596         69          0          0     0.0453     0.0318\n",
      " GlassGreen_NoDamNoDir       8596         75          0          0     0.0404     0.0384\n",
      "   GlassGreen_NoDamDir       8596        725      0.387      0.794      0.581      0.499\n",
      "   GlassGreen_DamNoDir       8596          2          1          0          0          0\n",
      "     GlassGreen_DamDir       8596        124     0.0677      0.177     0.0733     0.0494\n",
      "GlassTransparency_NoDamNoDir       8596        199      0.541      0.407      0.458      0.428\n",
      "GlassTransparency_NoDamDir       8596        909      0.405      0.754      0.529      0.438\n",
      "GlassTransparency_DamNoDir       8596         18          1          0          0          0\n",
      "GlassTransparency_DamDir       8596        120          0          0     0.0509     0.0372\n",
      "Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\recycle\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# YOLO 전이 학습\n",
    "from ultralytics import YOLO\n",
    "import shutil, os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "model.train(data='D:/python-ai-data/recycle_data.yaml', epochs=1, patience=3, batch=64, imgsz=640, \n",
    "            name='recycle', exist_ok=True, device=0)\n",
    "\n",
    "# if os.path.isdir('/content/drive/MyDrive/KCC_2nd_project/models/recycle'):\n",
    "#     shutil.rmtree('/content/drive/MyDrive/KCC_2nd_project/models/recycle')\n",
    "\n",
    "# shutil.copytree('/content/runs/detect/recycle/' , '/content/drive/MyDrive/KCC_2nd_project/models/recycle/')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea531e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google drive의 모델 파일을 불러들여 다시 전이 학습\n",
    "# 학습 완료 시 다시 google drive로 모델 파일 이동\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import shutil, os\n",
    "\n",
    "model = YOLO('/content/drive/MyDrive/KCC_2nd_project/models/recycle/weights/best.pt')\n",
    "\n",
    "model.train(data='/content/data/recycle_data.yaml', epochs=3, patience=3, batch=64, imgsz=640, name='recycle', exist_ok=True)\n",
    "\n",
    "# if os.path.isdir('/content/drive/MyDrive/KCC_2nd_project/models/recycle'):\n",
    "#     shutil.rmtree('/content/drive/MyDrive/KCC_2nd_project/models/recycle')\n",
    "\n",
    "# shutil.copytree('/content/runs/detect/recycle/' , '/content/drive/MyDrive/KCC_2nd_project/models/recycle/')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 값 확인\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import shutil, os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = YOLO('/content/drive/MyDrive/KCC_2nd_project/models/recycle/weights/best.pt')\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    results = model('/content/data/val/images/' + os.listdir('/content/data/val/images/')[i])\n",
    "\n",
    "    # Show the results\n",
    "    for r in results:\n",
    "        im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "        im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "        plt.imshow(im)\n",
    "        plt.show()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
